{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c2360d3-5f7d-4773-9aa4-1bb2ec29af83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b238b28-f335-4f23-87a7-c8c4a9a26912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (18510, 12)\n",
      "\n",
      "\n",
      "                      Facility Name  Facility ID State            Measure Name  \\\n",
      "0  SOUTHEAST HEALTH MEDICAL CENTER        10001    AL       READM-30-AMI-HRRP   \n",
      "1  SOUTHEAST HEALTH MEDICAL CENTER        10001    AL      READM-30-CABG-HRRP   \n",
      "2  SOUTHEAST HEALTH MEDICAL CENTER        10001    AL        READM-30-HF-HRRP   \n",
      "3  SOUTHEAST HEALTH MEDICAL CENTER        10001    AL  READM-30-HIP-KNEE-HRRP   \n",
      "4  SOUTHEAST HEALTH MEDICAL CENTER        10001    AL        READM-30-PN-HRRP   \n",
      "\n",
      "   Number of Discharges  Footnote  Excess Readmission Ratio  \\\n",
      "0                 296.0       NaN                    0.9483   \n",
      "1                 151.0       NaN                    0.9509   \n",
      "2                 681.0       NaN                    1.0597   \n",
      "3                   NaN       NaN                    0.9654   \n",
      "4                 490.0       NaN                    0.9715   \n",
      "\n",
      "   Predicted Readmission Rate  Expected Readmission Rate  \\\n",
      "0                     13.0146                    13.7235   \n",
      "1                      9.6899                    10.1898   \n",
      "2                     21.5645                    20.3495   \n",
      "3                      4.2680                     4.4211   \n",
      "4                     16.1137                    16.5863   \n",
      "\n",
      "  Number of Readmissions  Start Date    End Date  \n",
      "0                     36  07/01/2020  06/30/2023  \n",
      "1                     13  07/01/2020  06/30/2023  \n",
      "2                    151  07/01/2020  06/30/2023  \n",
      "3      Too Few to Report  07/01/2020  06/30/2023  \n",
      "4                     77  07/01/2020  06/30/2023  \n",
      "\n",
      "\n",
      " Facility Name                  object\n",
      "Facility ID                     int64\n",
      "State                          object\n",
      "Measure Name                   object\n",
      "Number of Discharges          float64\n",
      "Footnote                      float64\n",
      "Excess Readmission Ratio      float64\n",
      "Predicted Readmission Rate    float64\n",
      "Expected Readmission Rate     float64\n",
      "Number of Readmissions         object\n",
      "Start Date                     object\n",
      "End Date                       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('FY_2025_Hospital_Readmissions_Reduction_Program_Hospital.csv')\n",
    "print(\"Initial data shape:\", df.shape)\n",
    "print(\"\\n\\n\", df.head())\n",
    "print(\"\\n\\n\", df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65ed9f08-d202-41d9-a464-fe0f0959bacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING OF DATA\n",
    "df['Number of Readmissions'] = pd.to_numeric(df['Number of Readmissions'], errors='coerce')\n",
    "\n",
    "# Drop 'Number of Readmissions' that have 'Too Few to Report\" and empty 'Excess Readmission ratio' \n",
    "df = df.dropna(subset=['Number of Readmissions'])\n",
    "df = df.dropna(subset=['Excess Readmission Ratio'])\n",
    "\n",
    "# Filling in empty comlumns with set string\n",
    "df['Footnote'] = df['Footnote'].fillna('No notes')\n",
    "\n",
    "# Have to encode all categorical to numbers for random forest\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype(str)\n",
    "    unique_values = df[col].unique()\n",
    "    encoder = {val: idx for idx, val in enumerate(unique_values)}\n",
    "    df[col] = df[col].map(encoder)\n",
    "    label_encoders[col] = encoder\n",
    "\n",
    "# Drop dates since its the same time period\n",
    "df = df.drop(columns=['Start Date', 'End Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b342b499-1d8f-4ee9-addb-8ce742407b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Cleanse data shape: (8121, 10)\n",
      "\n",
      "\n",
      "    Facility Name  Facility ID  State  Measure Name  Number of Discharges  \\\n",
      "0              0        10001      0             0                 296.0   \n",
      "1              0        10001      0             1                 151.0   \n",
      "2              0        10001      0             2                 681.0   \n",
      "4              0        10001      0             3                 490.0   \n",
      "5              0        10001      0             4                 130.0   \n",
      "\n",
      "   Footnote  Excess Readmission Ratio  Predicted Readmission Rate  \\\n",
      "0         0                    0.9483                     13.0146   \n",
      "1         0                    0.9509                      9.6899   \n",
      "2         0                    1.0597                     21.5645   \n",
      "4         0                    0.9715                     16.1137   \n",
      "5         0                    0.9330                     15.4544   \n",
      "\n",
      "   Expected Readmission Rate  Number of Readmissions  \n",
      "0                    13.7235                    36.0  \n",
      "1                    10.1898                    13.0  \n",
      "2                    20.3495                   151.0  \n",
      "4                    16.5863                    77.0  \n",
      "5                    16.5637                    16.0  \n",
      "\n",
      "\n",
      " Facility Name                   int64\n",
      "Facility ID                     int64\n",
      "State                           int64\n",
      "Measure Name                    int64\n",
      "Number of Discharges          float64\n",
      "Footnote                        int64\n",
      "Excess Readmission Ratio      float64\n",
      "Predicted Readmission Rate    float64\n",
      "Expected Readmission Rate     float64\n",
      "Number of Readmissions        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Post Cleanse data shape:\", df.shape)\n",
    "print(\"\\n\\n\", df.head())\n",
    "print(\"\\n\\n\", df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "508d71a5-577c-4ae0-8a52-9458f341ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targetting high cost risk facilities where readmission ratio is greater than 1\n",
    "df['High_Cost_Risk'] = (df['Excess Readmission Ratio'] > 1).astype(int)\n",
    "\n",
    "X = df.drop(columns=['High_Cost_Risk']).values\n",
    "y = df['High_Cost_Risk'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea1c5c3a-fce9-405c-a799-a76370b13ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature_idx=None, threshold=None, left=None, right=None, *, value=None):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None\n",
    "\n",
    "# Recursively building the decision tree\n",
    "def build_tree(X, y, depth=0, max_depth=10):\n",
    "    if len(set(y)) == 1 or depth >= max_depth:\n",
    "        leaf_value = Counter(y).most_common(1)[0][0]\n",
    "        return Node(value=leaf_value)\n",
    "\n",
    "    best_feat, best_thresh = best_split(X, y)\n",
    "\n",
    "    if best_feat is None:\n",
    "        leaf_value = Counter(y).most_common(1)[0][0]\n",
    "        return Node(value=leaf_value)\n",
    "\n",
    "    X_left, y_left, X_right, y_right = split_dataset(X, y, best_feat, best_thresh)\n",
    "\n",
    "    left_child = build_tree(X_left, y_left, depth + 1, max_depth)\n",
    "    right_child = build_tree(X_right, y_right, depth + 1, max_depth)\n",
    "\n",
    "    return Node(feature_idx=best_feat, threshold=best_thresh, left=left_child, right=right_child)\n",
    "\n",
    "def predict_tree(x, tree):\n",
    "    if tree.is_leaf_node():\n",
    "        return tree.value\n",
    "    if x[tree.feature_idx] <= tree.threshold:\n",
    "        return predict_tree(x, tree.left)\n",
    "    else:\n",
    "        return predict_tree(x, tree.right)\n",
    "\n",
    "def predict(X, tree):\n",
    "    return np.array([predict_tree(x, tree) for x in X])\n",
    "\n",
    "def gini(y):\n",
    "    counts = np.bincount(y)\n",
    "    probabilities = counts / len(y)\n",
    "    return 1 - np.sum(probabilities ** 2)\n",
    "\n",
    "def split_dataset(X, y, feature_idx, threshold):\n",
    "    left_indices = X[:, feature_idx] <= threshold\n",
    "    right_indices = X[:, feature_idx] > threshold\n",
    "    return X[left_indices], y[left_indices], X[right_indices], y[right_indices]\n",
    "\n",
    "def best_split(X, y):\n",
    "    best_gain = -1\n",
    "    split_idx, split_threshold = None, None\n",
    "    n_features = X.shape[1]\n",
    "\n",
    "    for feature_idx in range(n_features):\n",
    "        values = np.unique(X[:, feature_idx])\n",
    "        for threshold in values:\n",
    "            X_left, y_left, X_right, y_right = split_dataset(X, y, feature_idx, threshold)\n",
    "            if len(y_left) == 0 or len(y_right) == 0:\n",
    "                continue\n",
    "\n",
    "            p = len(y_left) / len(y)\n",
    "            gain = gini(y) - (p * gini(y_left) + (1 - p) * gini(y_right))\n",
    "\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                split_idx = feature_idx\n",
    "                split_threshold = threshold\n",
    "\n",
    "    return split_idx, split_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a1c5c1cf-2ac0-49e5-8ec2-9dc83d68ce02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return np.sum(y_true == y_pred) / len(y_true)\n",
    "\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    unique_classes = np.unique(y_true)\n",
    "    matrix = np.zeros((len(unique_classes), len(unique_classes)), dtype=int)\n",
    "\n",
    "    for true_label, pred_label in zip(y_true, y_pred):\n",
    "        matrix[true_label][pred_label] += 1\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "15dc5fde-4e43-41d0-b82b-d75d3d240aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy: 1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3667    0]\n",
      " [   0 4454]]\n"
     ]
    }
   ],
   "source": [
    "tree = build_tree(X, y, max_depth=10)\n",
    "\n",
    "predictions = predict(X, tree)\n",
    "\n",
    "print(f\"\\nModel Accuracy: {accuracy(y, predictions):.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix_manual(y, predictions))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8faea1ee-0cd4-4521-8048-34a942395b9f",
   "metadata": {},
   "source": [
    "QUESTION 7: Validation - K-folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5eaf2f9b-b138-4274-8b59-288b70bc0d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy: 1.0000\n",
      "Fold 2 Accuracy: 1.0000\n",
      "Fold 3 Accuracy: 1.0000\n",
      "Fold 4 Accuracy: 1.0000\n",
      "Fold 5 Accuracy: 1.0000\n",
      "\n",
      "Average K-Fold Accuracy: 1.0000\n",
      "\n",
      "\n",
      "\n",
      "Classification Report (across all folds):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3667\n",
      "           1       1.00      1.00      1.00      4454\n",
      "\n",
      "    accuracy                           1.00      8121\n",
      "   macro avg       1.00      1.00      1.00      8121\n",
      "weighted avg       1.00      1.00      1.00      8121\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overall Confusion Matrix:\n",
      "[[3667    0]\n",
      " [   0 4454]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=40)\n",
    "fold = 1\n",
    "accuracies = []\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    tree = build_tree(X_train, y_train, max_depth=10)\n",
    "\n",
    "    y_pred = predict(X_test, tree)\n",
    "\n",
    "    acc = accuracy(y_test, y_pred)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "    print(f\"Fold {fold} Accuracy: {acc:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "    all_y_true.extend(y_test)\n",
    "    all_y_pred.extend(y_pred)\n",
    "\n",
    "# metrics from validation\n",
    "print(f\"\\nAverage K-Fold Accuracy: {np.mean(accuracies):.4f}\")\n",
    "\n",
    "print(\"\\n\\n\\nClassification Report (across all folds):\")\n",
    "print(classification_report(all_y_true, all_y_pred))\n",
    "\n",
    "print(\"\\n\\n\\nOverall Confusion Matrix:\")\n",
    "print(confusion_matrix(all_y_true, all_y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
